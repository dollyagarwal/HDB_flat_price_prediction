{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final Preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOZ+2iv4xBcxV04tNXSRfpi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"mjfFf2yZtwP7"},"source":["import pandas as pd\n","import pandas as pd\n","import numpy as np\n","import sklearn.neighbors\n","from sklearn import metrics\n","from geopy.distance import geodesic\n","from google.colab import drive\n","drive.mount('/content/drive',force_remount=True )\n","location='/content/drive/My Drive/CS 5228 Project/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k2kbYlLfugtm"},"source":["# Reading raw Training data and Testing data"]},{"cell_type":"code","metadata":{"id":"crxSC83VuxnL"},"source":["resale_data=pd.read_csv('{}train.csv/train.csv'.format(location))\n","df_r = pd.DataFrame(resale_data)\n","\n","test_data=pd.read_csv('{}test.csv/test.csv'.format(location))\n","df_test = pd.DataFrame(test_data)\n","\n","comm_center=pd.read_csv('{}auxiliary-data/sg-commerical-centres.csv'.format(location))\n","df_c = pd.DataFrame(comm_center)\n","\n","primary_school=pd.read_csv('{}auxiliary-data/sg-primary-schools.csv'.format(location))\n","df_pschool=pd.DataFrame(primary_school)\n","\n","demographics = pd.read_csv('{}auxiliary-data/sg-population-demographics.csv'.format(location))\n","df_demographics = pd.DataFrame(demographics)\n","\n","hawkers = pd.read_csv('{}auxiliary-data/sg-gov-markets-hawker-centres.csv'.format(location))\n","df_hawkers = pd.DataFrame(hawkers)\n","\n","malls = pd.read_csv('{}auxiliary-data/sg-shopping-malls.csv'.format(location))\n","df_malls = pd.DataFrame(malls)\n","\n","mrt = pd.read_csv('{}auxiliary-data/sg-train-stations.csv'.format(location))\n","df_mrt = pd.DataFrame(mrt)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjLioYNsvWq9"},"source":["# Data Cleaning and Preprocessing Methods"]},{"cell_type":"markdown","metadata":{"id":"gaL40FYlvdVZ"},"source":["\n","\n","1.   Remove elevation and eco-category as identified in EDA \n","2.   Preprocess flat_type and remove hyphen(-)\n","3.   Create a new column storey_mid to convert the range into the mean \n","4.   Split sale_year into sale_year(YYYY) and sale_month(MM)\n","5.   Calculate the lease period as this will determine how much time is left for the lease to end \n","6.   Convert cateogrical flat_types and flat_model into ordinal attribute  \n","7.   Check if the town is a mature town or not\n","8.   Convert region into ordinal attribute\n","9.   Calculate demographics percentages \n"]},{"cell_type":"code","metadata":{"id":"CE8RxYp2vcAG"},"source":["def data_preprocessing(X):\n","    X.drop(['elevation','eco_category'],axis='columns',inplace=True)\n","    X['flat_type']=X['flat_type'].str.replace(r'\\-', ' ')\n","    X['storey_low'] = X['storey_range'].apply(lambda x: x.split(\" \")[0]).astype('int')\n","    X['storey_high'] = X['storey_range'].apply(lambda x: x.split(\" \")[2]).astype('int')\n","    X['storey_mid'] = ((X['storey_low']+X['storey_high'])/2).astype(int)\n","    X.drop(['storey_high','storey_low'],axis='columns',inplace=True)\n","    X['sale_year']=X['month'].apply(lambda x: x.split(\"-\")[0]).astype(int)\n","    X['sale_month']=X['month'].apply(lambda x: x.split(\"-\")[1]).astype(int)\n","    X['lease_period'] = (99- (X['sale_year'] - X['lease_commence_date']))\n","\n","    flat_type_ord = { '1 room':1, '2 room': 2, '3 room': 3, '4 room': 4, '5 room': 5, 'executive': 6, 'multi generation':7}\n","    flat_model_ord={\n","    'type s2':3, 'type s1':3,'premium apartment loft':3,'dbss':3,'terrace':3,'premium maisonette':3,'multi generation':3,\n","    'maisonette':2,'model a maisonette':2,'improved maisonette':2,'apartment':2,'adjoined flat':2,'premium apartment':2,\n","    'improved':1,'model a2':1,'model a':1,'standard':1,'new generation':1,'simplified':1,'2 room':1}\n","\n","    X['flat_type_ord']= X['flat_type'].map(flat_type_ord) #pd.Series(bedrooms[x] for x in df_train['flat_type'])\n","    X['flat_model_ord']=X['flat_model'].map(flat_model_ord) #pd.Series(bathrooms[x] for x in df_train['flat_type'])\n","    \n","    mature_towns=['ang mo kio','bedok','bishan','bukit merah','bukit timah','central area','clementi','geylang',\n","    'kallang/whampoa','marine parade','pasir ris','queenstown','serangoon','tampines','toa payoh',]\n","\n","    non_mature_towns=['bukit batok','bukit panjang','choa chu kang','hougang','jurong east',\n","    'jurong west','punggol','sembawang','sengkang','woodlands','yishun']  #Removed Tengah as it is not in our dataset\n","    X['mature_town']=X['town'].isin(mature_towns).astype(int)\n","    \n","    dic = {'north region':1 , 'west region':2,'east region':3,'north-east region':4,'central region':5}\n","    X.region = x.region.map(dic)\n","    \n","    X = calculate_population_count(df_demographics, X)\n","    return X\n","\n","def calculate_population_count(df_demographics, df_X):\n","    \n","    #group by planning-area and sum counts\n","    df_demo_grouped = df_demographics.groupby(['plannin_area', 'age_group'], as_index=False).sum()\n","    #take the upper value in age_group as age, eg: age = [15-19] = 15  \n","    df_demo_grouped[\"age\"] = df_demo_grouped[\"age_group\"].apply(lambda x: x.split(\"-\")[0][0:2]).astype('int')\n","\n","    #filter population based on age \n","    #calculate counts demographics counts in each area \n","    #calculate children(age <20), working adults(age:20-60), retired(age>60)\n","    children = df_demo_grouped.groupby('plannin_area').apply(lambda x: x[x[\"age\"] < 20].sum()[\"count\"])\n","    adults = df_demo_grouped.groupby('plannin_area').apply(lambda x: x[(x.age >= 20) & (x.age < 59)].sum()[\"count\"])\n","    retired = df_demo_grouped.groupby('plannin_area').apply(lambda x: x[x[\"age\"] >= 60].sum()[\"count\"])\n","\n","    #create a new dataframe with only planning_area and population counts\n","    df_population = pd.DataFrame()\n","    total_children = children.sum()\n","    total_adults = adults.sum()\n","    total_retired = retired.sum()\n","\n","    df_population[\"childrenPerc\"] = (children/total_children)*100\n","    df_population[\"adultsPerc\"] = (adults/total_adults)*100\n","    df_population[\"retiredPerc\"] = (retired/total_retired)*100\n","    df_population[\"planning_area\"] = df_demo_grouped[\"plannin_area\"].unique()\n","\n","    df_hdb_population = df_X.merge(df_population, how='left', on='planning_area')\n","    return df_hdb_population"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NMUYJw0_1Mp9"},"source":["10. Calculate number of facilities in the given radius. The radius value for each of the auxiliary feature is identified in EDA \n","11. Calculate the minimum distance between the HDB and closest auxiliary facility\n"]},{"cell_type":"code","metadata":{"id":"CLswY9zdxSSR"},"source":["def calculate_geopy_distance(df_data, df_aux, radius,feature_title):\n","    list_of_lat = df_data['latitude']\n","    list_of_long = df_data['longitude']\n","    aux_lat = df_aux['lat']\n","    aux_long = df_aux['lng']\n","    # Zipping the respective Lat and Long lists together as a list of tuples\n","    list_of_coordinates = []\n","    for lat, long in zip(list_of_lat, list_of_long):\n","        list_of_coordinates.append((lat,long))\n","        \n","    list_of_aux_coordinates = []\n","    for lat, long in zip(aux_lat, aux_long):\n","        list_of_aux_coordinates.append((lat, long))\n","\n","    list_of_dist_aux = []\n","    min_dist_aux = []\n","    n_neighbors = []\n","    for origin in list_of_coordinates:\n","        for destination in range(0, len(list_of_aux_coordinates)):\n","            list_of_dist_aux.append(geodesic(origin,list_of_aux_coordinates[destination]).meters)\n","        \n","        #Find the minimum distance from the list of distances calculated above\n","        shortest = (min(list_of_dist_mrt))\n","        #Find the number of neighboring facitilies within a given radius \n","        neighboring_aux = list(filter(lambda x: x < radius,list_of_dist_aux))\n","        \n","        n_neighbors.append(len(neighboring_aux))\n","        min_dist_aux.append(shortest)\n","        list_of_dist_aux.clear()\n","\n","    n_neighbors_title = \"n_neighbors_{}\".format(feature_title)\n","    df_data[n_neighbors_title] = n_neighbors\n","\n","    min_dist_title = \"min_dist_{}\".format(feature_title)\n","    df_data[min_dist_title] = min_dist_aux"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aSIlIM1e3BF8"},"source":["# Perform Preprocessing on Training Data"]},{"cell_type":"code","metadata":{"id":"dFF071kI4o6v"},"source":["train_data = data_preprocessing(df_r)\n","calculate_geopy_distance(train_data,df_mrt,1250,\"mrt\")\n","calculate_geopy_distance(train_data,df_malls,1300,\"mrt\")\n","calculate_geopy_distance(train_data,df_hawkers,1600,\"mrt\")\n","calculate_geopy_distance(train_data,df_pschool,1500,\"mrt\")\n","calculate_geopy_distance(train_data,df_c,2000,\"mrt\")\n","train_data.to_csv('{}/final codes/Data/clean_train.csv'.format(location))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FS17YOnq5JJu"},"source":["# Perform Preprocessing on Test Data"]},{"cell_type":"code","metadata":{"id":"RuknKDI14Z83"},"source":["test_data = data_preprocessing(df_test)\n","calculate_geopy_distance(test_data,df_mrt,1250,\"mrt\")\n","calculate_geopy_distance(test_data,df_malls,1300,\"mrt\")\n","calculate_geopy_distance(test_data,df_hawkers,1600,\"mrt\")\n","calculate_geopy_distance(test_data,df_pschool,1500,\"mrt\")\n","calculate_geopy_distance(test_data,df_c,2000,\"mrt\")\n","test_data.to_csv('{}/final codes/Data/clean_test.csv'.format(location))"],"execution_count":null,"outputs":[]}]}